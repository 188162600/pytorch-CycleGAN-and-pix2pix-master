{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bkkaggle/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VIGyIus8Vr7"
   },
   "source": [
    "Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRm-USlsHgEV"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (86066964.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python train.py  --names monet2photo --dataroot ./datasets/monet2photo --batch_size 1 --display_freq 1 --separate_classifier_backward True --accurate_classifier_backward True\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!python train.py  --names monet2photo --dataroot ./datasets/monet2photo --batch_size 2 --display_freq 1 --separate_classifier_backward True --accurate_classifier_backward True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "accurate_classifier_backward: False                         \t[default: False]\n",
      "               batch_size: 2                             \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "blocks_step_classifier_encoder: resnet50                      \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ['./datasets/monet2photo']    \t[default: []]\n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 1                             \t[default: 400]\n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "downsample_step_classifier_encoder: resnet50                      \n",
      "           encoder_max_nc: 128                           \n",
      "           encoder_min_nc: 64                            \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                    names: ['monet2photo']               \t[default: []]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "new_steps_additional_train: 0.5                           \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: instance                      \n",
      "            num_new_steps: 16                            \n",
      "       num_options_blocks: 12                            \n",
      "   num_options_downsample: 4                             \n",
      "     num_options_upsample: 4                             \n",
      "          num_saved_steps: 128                           \n",
      "        num_shared_blocks: 4                             \n",
      "    num_shared_downsample: 0                             \n",
      "      num_shared_upsample: 0                             \n",
      "              num_threads: 4                             \n",
      "             num_tracking: 4096                          \n",
      "         optimize_C_epoch: []                            \n",
      "         optimize_D_epoch: []                            \n",
      "         optimize_G_epoch: []                            \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             project_name: monet2photo                   \t[default: None]\n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "separate_classifier_backward: True                          \t[default: True]\n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "upsample_step_classifier_encoder: resnet50                      \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "dataset [UnalignedDataset] was created\n",
      "generate_batches 0\n",
      "<data.CustomDatasetDataLoader object at 0x0000026783E67FD0>\n",
      "The number of training images = 6287\n",
      "num_options_each_layer [4, 12, 4]\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), groups=4) normal 0.02\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4) normal 0.02\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4) normal 0.02\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "init SelectiveConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), groups=12) normal 0.02\n",
      "initialize network with normal\n",
      "init SelectiveConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), groups=4) normal 0.02\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "init SelectiveConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), groups=4) normal 0.02\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "init SelectiveConv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), groups=4) normal 0.02\n",
      "initialize network with normal\n",
      "dummy 196608\n",
      "self.features.shape torch.Size([1, 64, 256, 256])\n",
      "self.features.shape torch.Size([1, 128, 128, 128])\n",
      "self.features.shape torch.Size([1, 256, 64, 64])\n",
      "dummy 1048576\n",
      "dummy 1048576\n",
      "self.features.shape torch.Size([1, 3, 256, 256])\n",
      "dummy 196608\n",
      "self.features.shape torch.Size([1, 64, 256, 256])\n",
      "self.features.shape torch.Size([1, 128, 128, 128])\n",
      "self.features.shape torch.Size([1, 256, 64, 64])\n",
      "dummy 1048576\n",
      "dummy 1048576\n",
      "self.features.shape torch.Size([1, 3, 256, 256])\n",
      "dummy 196608\n",
      "self.features.shape torch.Size([1, 64, 256, 256])\n",
      "self.features.shape torch.Size([1, 128, 128, 128])\n",
      "self.features.shape torch.Size([1, 256, 64, 64])\n",
      "dummy 1048576\n",
      "dummy 1048576\n",
      "self.features.shape torch.Size([1, 3, 256, 256])\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [CycleGANModel] was created\n",
      "[torch.Size([3, 256, 256]), torch.Size([3, 256, 256]), torch.Size([3, 256, 256]), (1, 10, 4)]\n",
      "device cuda:0\n",
      "[torch.Size([256, 64, 64]), torch.Size([256, 64, 64]), torch.Size([256, 64, 64]), (1, 8, 12)]\n",
      "device cuda:0\n",
      "[torch.Size([256, 64, 64]), torch.Size([256, 64, 64]), torch.Size([256, 64, 64]), (1, 9, 4)]\n",
      "device cuda:0\n",
      "device cuda:0\n",
      "device cuda:0\n",
      "device cuda:0\n",
      "---------- Networks initialized -------------\n",
      "[Network D_A] Total number of parameters : 2.765 M\n",
      "[Network D_B] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n",
      "---------- Networks initialized -------------\n",
      "[Network D_A] Total number of parameters : 2.765 M\n",
      "[Network D_B] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n",
      "create web directory ./checkpoints\\monet2photo\\web...\n",
      "save_filename check_net_monet2photo_D_A.pth ./checkpoints\\monet2photo\n",
      "save_filename check_net_monet2photo_D_B.pth ./checkpoints\\monet2photo\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "[0] [0] [0]\n",
      "generate_batches 3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "c:\\Users\\18816\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\pytorch-CycleGAN-and-pix2pix-master\\train.py\", line 80, in <module>\n",
      "    model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
      "  File \"c:\\pytorch-CycleGAN-and-pix2pix-master\\models\\cycle_gan_model.py\", line 404, in optimize_parameters\n",
      "    self.backward_G(data)             # calculate gradients for G_A and G_B\n",
      "  File \"c:\\pytorch-CycleGAN-and-pix2pix-master\\models\\cycle_gan_model.py\", line 370, in backward_G\n",
      "    data.task_G_A.optimize_layers(data.loss_G)\n",
      "  File \"c:\\pytorch-CycleGAN-and-pix2pix-master\\meta\\task.py\", line 148, in optimize_layers\n",
      "    self._backward(loss)\n",
      "  File \"c:\\pytorch-CycleGAN-and-pix2pix-master\\meta\\task.py\", line 143, in _backward\n",
      "    loss.mean().backward()\n",
      "  File \"c:\\Users\\18816\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\18816\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python train.py  --names monet2photo --dataroot ./datasets/monet2photo --batch_size 2 --display_freq 1 --separate_classifier_backward True --accurate_classifier_backward False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z1EySlOXwwoa"
   },
   "outputs": [],
   "source": [
    "!python train.py  --names monet2photo --dataroot ./datasets/monet2photo --batch_size 2 --display_freq 1 --separate_classifier_backward False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CycleGAN",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
